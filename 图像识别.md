https://huggingface.co/datasets/EduardoPacheco/FoodSeg103  Dataset Card for FoodSeg103
Dataset Summary
FoodSeg103 is a large-scale benchmark for food image segmentation. It contains 103 food categories and 7118 images with ingredient level pixel-wise annotations. The dataset is a curated sample from Recipe1M and annotated and refined by human annotators. The dataset is split into 2 subsets: training set, validation set. The training set contains 4983 images and the validation set contains 2135 images.

Supported Tasks and Leaderboards
No leaderboard is available for this dataset at the moment.

Dataset Structure
Data categories
id	ingridient
0	background
1	candy
2	egg tart
3	french fries
4	chocolate
5	biscuit
6	popcorn
7	pudding
8	ice cream
9	cheese butter
10	cake
11	wine
12	milkshake
13	coffee
14	juice
15	milk
16	tea
17	almond
18	red beans
19	cashew
20	dried cranberries
21	soy
22	walnut
23	peanut
24	egg
25	apple
26	date
27	apricot
28	avocado
29	banana
30	strawberry
31	cherry
32	blueberry
33	raspberry
34	mango
35	olives
36	peach
37	lemon
38	pear
39	fig
40	pineapple
41	grape
42	kiwi
43	melon
44	orange
45	watermelon
46	steak
47	pork
48	chicken duck
49	sausage
50	fried meat
51	lamb
52	sauce
53	crab
54	fish
55	shellfish
56	shrimp
57	soup
58	bread
59	corn
60	hamburg
61	pizza
62	hanamaki baozi
63	wonton dumplings
64	pasta
65	noodles
66	rice
67	pie
68	tofu
69	eggplant
70	potato
71	garlic
72	cauliflower
73	tomato
74	kelp
75	seaweed
76	spring onion
77	rape
78	ginger
79	okra
80	lettuce
81	pumpkin
82	cucumber
83	white radish
84	carrot
85	asparagus
86	bamboo shoots
87	broccoli
88	celery stick
89	cilantro mint
90	snow peas
91	cabbage
92	bean sprouts
93	onion
94	pepper
95	green beans
96	French beans
97	king oyster mushroom
98	shiitake
99	enoki mushroom
100	oyster mushroom
101	white button mushroom
102	salad
103	other ingredients
Data Splits
This dataset only contains two splits. A training split and a validation split with 4983 and 2135 images respectively.

Dataset Creation
Curation Rationale
Select images from a large-scale recipe dataset and annotate them with pixel-wise segmentation masks.

Source Data
The dataset is a curated sample from Recipe1M.

Initial Data Collection and Normalization
After selecting the source of the data two more steps were added before image selection.

Recipe1M contains 1.5k ingredient categoris, but only the top 124 categories were selected + a 'other' category (further became 103).
Images should contain between 2 and 16 ingredients.
Ingredients should be visible and easy to annotate.
Which then resulted in 7118 images.

Annotations
Annotation process
Third party annotators were hired to annotate the images respecting the following guidelines:

Tag ingredients with appropriate categories.
Draw pixel-wise masks for each ingredient.
Ignore tiny regions (even if contains ingredients) with area covering less than 5% of the image.
Refinement process
The refinement process implemented the following steps:

Correct mislabelled ingredients.
Deleting unpopular categories that are assigned to less than 5 images (resulting in 103 categories in the final dataset).
Merging visually similar ingredient categories (e.g. orange and citrus)
Who are the annotators?
A third party company that was not mentioned in the paper.

Additional Information
Dataset Curators
Authors of the paper A Large-Scale Benchmark for Food Image Segmentation.

Licensing Information
Apache 2.0 license.

Citation Information
@inproceedings{wu2021foodseg,
    title={A Large-Scale Benchmark for Food Image Segmentation},
    author={Wu, Xiongwei and Fu, Xin and Liu, Ying and Lim, Ee-Peng and Hoi, Steven CH and Sun, Qianru},
    booktitle={Proceedings of ACM international conference on Multimedia},
    year={2021}
}# 安装依赖库
!pip install git+https://github.com/openai/CLIP.git -q
!pip install transformers -q
!pip install openfoodfacts -q
!pip install torchvision matplotlib -q

import torch
import clip
from PIL import Image
import matplotlib.pyplot as plt
import requests
from io import BytesIO
from transformers import pipeline
import openfoodfacts

# 设置随机种子保证可重复性
torch.manual_seed(42)

# ------------------
# 食材识别模块
# ------------------
def image_recognition():
    # 加载CLIP模型
    device = "cuda" if torch.cuda.is_available() else "cpu"
    model, preprocess = clip.load("ViT-B/32", device=device)
    
    # 定义食材候选列表（可根据需要扩展）
    ingredient_list = [
        "apple", "banana", "carrot", "broccoli", "tomato",
        "potato", "onion", "chicken", "egg", "flour",
        "milk", "cheese", "fish", "beef", "sugar"
    ]
    
    # 加载测试图片（这里使用示例图片，可替换为任意图片URL）
    image_url = "https://storage.googleapis.com/sfr-vision-language-research/CLIP/benchmark.jpg"  # 示例图片包含苹果和胡萝卜
    response = requests.get(image_url)
    img = Image.open(BytesIO(response.content))
    
    # 预处理和模型推理
    image = preprocess(img).unsqueeze(0).to(device)
    text = clip.tokenize([f"a photo of {ingredient}" for ingredient in ingredient_list]).to(device)
    
    with torch.no_grad():
        image_features = model.encode_image(image)
        text_features = model.encode_text(text)
        logits_per_image, _ = model(image, text)
        probs = logits_per_image.softmax(dim=-1).cpu().numpy()
    
    # 获取预测结果
    top_k = 3
    top_indices = probs.argsort()[0][-top_k:][::-1]
    predicted_ingredients = [ingredient_list[i] for i in top_indices]
    
    # 显示结果（假设真实标签为已知）
    true_ingredients = ["apple", "carrot"]  # 示例图片真实标签
    
    plt.imshow(img)
    plt.axis('off')
    plt.title(f"Predicted: {', '.join(predicted_ingredients)}\nTrue: {', '.join(true_ingredients)}")
    plt.show()
    
    return predicted_ingredients

# ------------------
# 食谱推荐模块
# ------------------
def recipe_recommendation(ingredients):
    generator = pipeline('text-generation', model='gpt2-medium')
    
    prompt = f"Create a detailed recipe using {', '.join(ingredients)}:\n1."
    recipe = generator(
        prompt,
        max_length=300,
        num_return_sequences=1,
        temperature=0.7,
        top_p=0.9
    )
    
    print("\nGenerated Recipe:")
    print(recipe[0]['generated_text'])

# ------------------
# 营养分析模块
# ------------------
def nutritional_analysis(ingredients):
    print("\nNutritional Analysis (per 100g):")
    
    nutrition = {
        'energy': 0,
        'fat': 0,
        'carbohydrates': 0,
        'proteins': 0
    }
    
    for ingredient in ingredients:
        try:
            products = openfoodfacts.products.search(ingredient)
            if products['products']:
                product = products['products'][0]
                nutriments = product.get('nutriments', {})
                
                nutrition['energy'] += nutriments.get('energy-kcal_100g', 0) or 0
                nutrition['fat'] += nutriments.get('fat_100g', 0) or 0
                nutrition['carbohydrates'] += nutriments.get('carbohydrates_100g', 0) or 0
                nutrition['proteins'] += nutriments.get('proteins_100g', 0) or 0
        except:
            continue
    
    print(f"Calories: {nutrition['energy']:.1f} kcal")
    print(f"Fat: {nutrition['fat']:.1f} g")
    print(f"Carbohydrates: {nutrition['carbohydrates']:.1f} g")
    print(f"Proteins: {nutrition['proteins']:.1f} g")

# ------------------
# 主程序
# ------------------
if __name__ == "__main__":
    # 执行图像识别
    detected_ingredients = image_recognition()
    
    # 食谱推荐
    recipe_recommendation(detected_ingredients)
    
    # 营养分析
    nutritional_analysis(detected_ingredients)
