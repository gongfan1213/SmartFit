{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "012ec405-7294-4a8f-817c-23f70caffa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install dependencies\n",
    "!pip install --quiet transformers datasets accelerate evaluate\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSeq2SeqLM,\n",
    "    DataCollatorForSeq2Seq,\n",
    "    Seq2SeqTrainingArguments,\n",
    "    Seq2SeqTrainer\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0b9948aa-6c33-49fe-86ff-c39188cfba7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset columns: ['name', 'description', 'cuisine', 'course', 'diet', 'ingredients_name', 'ingredients_quantity', 'prep_time (in mins)', 'cook_time (in mins)', 'instructions', 'image_url']\n",
      "Example entry:\n",
      " {'name': 'Greek Style Broken Wheat Salad with Chickpeas, Fresh Mint & Feta - A Mediterranean Powerhouse', 'description': 'This Greek Style Broken Wheat Salad with Chickpeas, Fresh Mint & Feta is a refreshing and nutritious Mediterranean-inspired dish. The nutty flavor of broken wheat pairs perfectly with protein-rich chickpeas, fresh mint, and crumbly feta cheese, creating a balanced, fiber-packed meal. Lightly dressed with lemon juice and olive oil, this salad is a healthy option that bursts with flavor. It’s an ideal meal for lunch or dinner, or even as a side dish for a Mediterranean feast.', 'cuisine': 'Greek', 'course': 'World Breakfast', 'diet': 'Diabetic Friendly', 'ingredients_name': 'Broken Wheat (Dalia/ Godumai Rava), Kabuli Chana (White Chickpeas), Garlic, Onions, Carrot (Gajjar), Red Bell pepper (Capsicum), Broccoli, Cinnamon Powder (Dalchini), Lemon juice, Caster Sugar, Feta Cheese, Mint Leaves (Pudina), Extra Virgin Olive Oil, Salt and Pepper', 'ingredients_quantity': '1 cup Broken Wheat (Dalia/ Godumai Rava)  1/2 cup Kabuli Chana (White Chickpeas) , soaked for 8 hours and boiled  4 cloves Garlic , finely chopped  2 Onions , thinly sliced  1 Carrot (Gajjar) , finely chopped  1 Red Bell pepper (Capsicum) , finely chopped  1/2 cup Broccoli , cut into tiny florets  1/8 teaspoon Cinnamon Powder (Dalchini)  3 tablespoons Lemon juice  1/2 teaspoon Caster Sugar  1/2 cup Feta Cheese , crumbled  1/4 cup Mint Leaves (Pudina) , chopped  3 tablespoon Extra Virgin Olive Oil Salt and Pepper , for seasoning', 'prep_time (in mins)': 20.0, 'cook_time (in mins)': 45.0, 'instructions': 'We begin making the Greek Style Broken Wheat Salad with Chickpeas Fresh Mint & Feta Recipe prep all the ingredients and keep ready.Cook the broken wheat in a pressure cooker with 1-1/2 cups of water for about 2 whistles on high heat. Turn the heat to low and simmer for 3 min and turn off the heat. Allow the pressure to release naturally.\\xa0Once cooked, drizzle olive oil over the wheat and gently fluff up with a fork.Cook the soaked chickpeas in the pressure cooker for about 40 minutes until it is soft and cooked completely. First cook on high for the first 4 whistles and then turn the heat to low and simmer to cook for another 30 minutes. Once done, allow it to cool and drain from its water and keep aside.\\xa0Heat oil in a pan over medium heat; add the carrots, broccoli and bell peppers and saute on high heat till it an al dente texture (is cooked but has a bite to it). Once done, turn off the heat and allow it to cool.In a large mixing bowl add all the ingredients from the cooked wheat, chickpeas, vegetables, mint, salt, feta and pepper and toss it over. Check for seasonings and add if it is required for more.Serve the Greek Style Broken Wheat Salad with Chickpeas Fresh Mint & Feta Recipe for a light and high protein lunch or dinner.', 'image_url': 'https://www.archanaskitchen.com/images/archanaskitchen/1-Author/sibyl_sunitha/Greek_Style_Broken_Wheat_Salad_with_Chickpeas_Fresh_Mint__Feta_Recipe_.jpg'}\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"BhavaishKumar112/Food_Recipe\")\n",
    "print(\"Dataset columns:\", dataset['train'].column_names)\n",
    "print(\"Example entry:\\n\", dataset['train'][0])  # inspect first example, then set the field names below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bb3a0e5f-f414-4cf7-affb-67126706f4b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example entry:\n",
      " 1 cup Broken Wheat (Dalia/ Godumai Rava)  1/2 cup Kabuli Chana (White Chickpeas) , soaked for 8 hours and boiled  4 cloves Garlic , finely chopped  2 Onions , thinly sliced  1 Carrot (Gajjar) , finely chopped  1 Red Bell pepper (Capsicum) , finely chopped  1/2 cup Broccoli , cut into tiny florets  1/8 teaspoon Cinnamon Powder (Dalchini)  3 tablespoons Lemon juice  1/2 teaspoon Caster Sugar  1/2 cup Feta Cheese , crumbled  1/4 cup Mint Leaves (Pudina) , chopped  3 tablespoon Extra Virgin Olive Oil Salt and Pepper , for seasoning\n"
     ]
    }
   ],
   "source": [
    "print(\"Example entry:\\n\", dataset['train'][0][dataset['train'].column_names[6]])  # inspect first example, then set the field names below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "31f1a94b-16b1-468c-811f-b460ad24385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SET THESE BASED ON CHECK ABOVE ===\n",
    "key_title = \"name\"                   # recipe title field\n",
    "key_ing_name = \"ingredients_name\"    # ingredient names field\n",
    "key_ing_qty  = \"ingredients_quantity\"# ingredient quantities field\n",
    "key_inst = \"instructions\"            # instructions field\n",
    "# ======================================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "290b959e-c425-4ad7-ba65-b0e0e862836d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Split into train/validation and filter null entries\n",
    "split = dataset[\"train\"].train_test_split(test_size=0.1, seed=42)\n",
    "train_ds = split[\"train\"].filter(\n",
    "    lambda x: x[key_ing_name] is not None and x[key_ing_qty] is not None and x[key_inst] is not None\n",
    ")\n",
    "eval_ds  = split[\"test\"].filter(\n",
    "    lambda x: x[key_ing_name] is not None and x[key_ing_qty] is not None and x[key_inst] is not None\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c28a2377-d34f-4f6d-9eff-da0d63d38d34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ae8b3c448ac40ab93ad7f4d6b86f04a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6385 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b4599fac4f64cbba8e7312b823f79c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/711 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4. Preprocess: build input-output pairs\n",
    "\n",
    "def preprocess(example):\n",
    "    title = example[key_title].strip()\n",
    "    names = example[key_ing_name].strip()\n",
    "    qtys  = example[key_ing_qty].strip()\n",
    "    instr = example[key_inst].strip().replace(\"\\n\", \" \")\n",
    "\n",
    "    # Input prompt uses ingredient names only\n",
    "    prompt = f\"Suggest a detailed recipe given ingredients: {names}.\"\n",
    "    # Target includes title, ingredients with quantities, and instructions\n",
    "    #name_list = [n.strip() for n in names.split(\",\")]\n",
    "    #qty_list  = [q.strip() for q in qtys.split(\",\")]\n",
    "    # ensure same length\n",
    "    #pairs = zip(name_list, qty_list) if len(name_list)==len(qty_list) else [(n, '') for n in name_list]\n",
    "    #ingredients_info = \"; \".join([f\"{n}: {q}\" for n, q in pairs])\n",
    "    target = (\n",
    "        f\"Recipe name: {title}\\n\"\n",
    "        f\"Ingredients & quantities: {qtys}\\n\"\n",
    "        f\"Instructions: {instr}\"\n",
    "    )\n",
    "    return {\"input_text\": prompt, \"target_text\": target}\n",
    "\n",
    "# Apply preprocessing\n",
    "train_ds = train_ds.map(preprocess, remove_columns=dataset['train'].column_names)\n",
    "eval_ds  = eval_ds.map(preprocess,  remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1844db6e-f533-4746-a95b-2d8a3c0d0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Preprocess: build input-output pairs\n",
    "\n",
    "def preprocess(example):\n",
    "    title = example[key_title].strip()\n",
    "    qtys  = example[key_ing_qty].strip()\n",
    "    instr = example[key_inst].strip().replace(\"\\n\", \" \")\n",
    "\n",
    "    # Input prompt uses ingredient names only\n",
    "    prompt = f\"Suggest a detailed recipe given ingredients: {names}.\"\n",
    "    \n",
    "    # Target includes title, ingredients with quantities, and instructions\n",
    "    target = (\n",
    "        f\"Recipe name: {title}\\n\"\n",
    "        f\"Ingredients & quantities: {qtys}\\n\"\n",
    "        f\"Instructions: {instr}\"\n",
    "    )\n",
    "    return {\"input_text\": prompt, \"target_text\": target}\n",
    "\n",
    "# Apply preprocessing\n",
    "train_ds = train_ds.map(preprocess, remove_columns=dataset['train'].column_names)\n",
    "eval_ds  = eval_ds.map(preprocess,  remove_columns=dataset['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "6b692024-75dc-4688-955c-d99f664a2b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Load tokenizer and model\n",
    "model_name = \"t5-base\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model     = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "df3c2938-f48e-45d0-b8d0-3a4bffc5f0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4d7eec0fee04c069b69dd37e04b1799",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6385 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5457fa320bf4bd0bf2829a4596efabc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/711 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Tokenize data\n",
    "def tokenize_fn(batch):\n",
    "    inputs  = tokenizer(batch[\"input_text\"],  max_length=512, truncation=True)\n",
    "    targets = tokenizer(batch[\"target_text\"], max_length=512, truncation=True)\n",
    "    inputs[\"labels\"] = targets[\"input_ids\"]\n",
    "    return inputs\n",
    "\n",
    "train_tok = train_ds.map(tokenize_fn, batched=True, remove_columns=[\"input_text\",\"target_text\"])\n",
    "eval_tok  = eval_ds.map(tokenize_fn,  batched=True, remove_columns=[\"input_text\",\"target_text\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "9084a981-7159-453d-ba03-2f14a8c7e9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Data collator\n",
    "\n",
    "from transformers import DataCollatorForSeq2Seq\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8c90c839-6857-4d0c-90bc-cacaa55abd97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend. Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: yangsunchengrui (yangsunchengrui-none). Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b51105179e80429bbae90acb78a926bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='Waiting for wandb.init()...\\r'), FloatProgress(value=0.011111111111111112, max=1.0…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.18.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>C:\\Users\\YSCR\\wandb\\run-20250424_163921-7z1lv73x</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/yangsunchengrui-none/recipes/runs/7z1lv73x' target=\"_blank\">drawn-shape-2</a></strong> to <a href='https://wandb.ai/yangsunchengrui-none/recipes' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/yangsunchengrui-none/recipes' target=\"_blank\">https://wandb.ai/yangsunchengrui-none/recipes</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/yangsunchengrui-none/recipes/runs/7z1lv73x' target=\"_blank\">https://wandb.ai/yangsunchengrui-none/recipes/runs/7z1lv73x</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/yangsunchengrui-none/recipes/runs/7z1lv73x?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x23586c4bf20>"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "# 初始化 W&B\n",
    "wandb.init(project=\"recipes\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b5069860-120d-47a1-a2b6-256ff2a4d8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. Training arguments\n",
    "from transformers import Seq2SeqTrainingArguments\n",
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"C:/Users/YSCR/Desktop/study/hkbu/semester2/7065/course project\",\n",
    "    eval_strategy=\"steps\",\n",
    "    eval_steps=500,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=1000,\n",
    "    logging_strategy=\"steps\",\n",
    "    logging_steps=200,\n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    "    num_train_epochs=3,\n",
    "    learning_rate=5e-5,\n",
    "    weight_decay=0.01,\n",
    "    predict_with_generate=True,\n",
    "    report_to=\"wandb\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "28b4295e-0103-46e9-b49d-0d6e5a088987",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\YSCR\\AppData\\Local\\Temp\\ipykernel_83184\\1866891417.py:3: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Seq2SeqTrainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Seq2SeqTrainer(\n"
     ]
    }
   ],
   "source": [
    "# 10. Trainer setup\n",
    "from transformers import Seq2SeqTrainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tok,\n",
    "    eval_dataset=eval_tok,\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f96ff4b7-c608-45cc-81f0-9b61d2ec9773",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.48.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='4791' max='4791' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [4791/4791 2:08:15, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>2.252300</td>\n",
       "      <td>1.882080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.032600</td>\n",
       "      <td>1.760895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.903700</td>\n",
       "      <td>1.697430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.834200</td>\n",
       "      <td>1.658525</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>1.822600</td>\n",
       "      <td>1.632445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>1.754700</td>\n",
       "      <td>1.611899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>1.766700</td>\n",
       "      <td>1.600562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>1.756900</td>\n",
       "      <td>1.589340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>1.757600</td>\n",
       "      <td>1.584737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=4791, training_loss=1.9127677036859476, metrics={'train_runtime': 7695.9095, 'train_samples_per_second': 2.489, 'train_steps_per_second': 0.623, 'total_flos': 2689576703262720.0, 'train_loss': 1.9127677036859476, 'epoch': 3.0})"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10. Train!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "faac0c86-49e9-44ae-b9b1-8eb107bd1f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fine-tuned model saved to C:/Users/YSCR/Desktop/study/hkbu/semester2/7065/course project/recipe_model\n"
     ]
    }
   ],
   "source": [
    "# 11. Save the fine-tuned model and tokenizer\n",
    "model.save_pretrained(\"C:/Users/YSCR/Desktop/study/hkbu/semester2/7065/course project/recipe_model\")\n",
    "tokenizer.save_pretrained(\"C:/Users/YSCR/Desktop/study/hkbu/semester2/7065/course project/recipe_model\")\n",
    "print(\"Fine-tuned model saved to C:/Users/YSCR/Desktop/study/hkbu/semester2/7065/course project/recipe_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b73e0ae9-86d8-4b15-bac1-f3e26eadcf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12. Test generation\n",
    "def generate_recipe(ingredients_list, max_length=256):\n",
    "    prompt = f\"Suggest a detailed recipe given ingredients: {ingredients_list}.\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    outputs = model.generate(**inputs, max_length=max_length, num_beams=4, early_stopping=True)\n",
    "    return tokenizer.decode(outputs[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "920f881d-e336-4019-93c0-6fe32f591f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe name: Tomato Basil Pesto Recipe Ingredients & quantities: 1 tomato , finely chopped 1 basil , finely chopped 2 cloves garlic , finely chopped 1 tablespoon olive oil Salt , to taste Instructions: To begin making the Tomato Basil Pesto Recipe, heat olive oil in a heavy bottomed pan over medium heat. Add the tomatoes, basil, garlic and saute for a few seconds.Add the tomatoes and saute for a few seconds.Add the tomatoes and saute for a few seconds.Add the tomatoes and saute for a few seconds.Add the tomatoes and saute for a few seconds.Add the tomatoes and saute for a few seconds.Add the tomatoes and saute for a few seconds until the tomatoes are soft and translucent.Add the basil and saute for a few seconds.Add the tomatoes and saute for a few seconds.Add the tomatoes and saute for a few seconds until the tomatoes are soft and translucent.Once the tomatoes are soft, add the garlic and saute for a few seconds until the tomatoes are soft and translucent.Once the tomatoes are soft, add the basil and saute for a few seconds until the tomatoes are soft and translucent.Serve the Basil Basil Basil Basil Salad along with a cup of coffee or tea.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "test_ing = \"tomato, basil, garlic, olive oil, salt\"\n",
    "print(generate_recipe(test_ing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "52ff8f5d-0f98-4c5e-8fa0-84f3f557a981",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe name: Soy Chicken Rice Recipe Ingredients & quantities: 2 cups chicken , cut into cubes 1 cup rice 1 teaspoon soy sauce Instructions: To begin making the Soy Chicken Rice Recipe, heat a pan with oil and add the chicken to the pan. Add the rice and soy sauce to the pan. Add the rice and soy sauce to the pan and cook until the rice is cooked through.Once the rice is cooked through, turn off the heat and allow the rice to cool down.Once the rice is cooked, add the rice and soy sauce to the pan and allow it to cool down.Serve Soy Chicken Rice Rice Recipe along with Soy Chicken Rice Recipe for a weeknight dinner.\n"
     ]
    }
   ],
   "source": [
    "#from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "#import torch\n",
    "\n",
    "# 1. 定义模型路径（替换为你的实际路径）\n",
    "#model_path = \"C:/Users/YSCR/Desktop/study/hkbu/semester2/7065/course project/recipe_model\"\n",
    "\n",
    "# 2. 加载模型和分词器\n",
    "#tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "#model = AutoModelForSeq2SeqLM.from_pretrained(model_path).to(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# 3. 定义生成函数\n",
    "#def generate_recipe(ingredients_list):\n",
    "    \"\"\"\n",
    "    输入食材列表，生成完整食谱\n",
    "    Input: ingredients list (e.g., \"tomato, onion, garlic\")\n",
    "    Output: Full recipe with name, ingredients, and instructions\n",
    "    \"\"\"\n",
    "    #prompt = f\"Suggest a detailed recipe given ingredients: {ingredients_list}.\"\n",
    "    #inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
    "    #outputs = model.generate(\n",
    "        #**inputs,\n",
    "        #max_length=512,          # 最大生成长度\n",
    "        #num_beams=4,             # 束搜索参数\n",
    "        #early_stopping=True      # 提前停止\n",
    "    #)\n",
    "    #return tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "# 4. 测试调用\n",
    "#test_ingredients = \"chicken, rice, soy sauce\"\n",
    "#print(generate_recipe(test_ingredients))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ad4d0d7-921f-4c5c-b8f5-2a431569bb5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recipe name: Tomato Basil Curry Recipe Ingredients & quantities: 1 tomato , sliced 1 teaspoon basil 1 teaspoon garlic 1 tablespoon olive oil salt , to taste Instructions: To begin making the Tomato Basil Curry Recipe, first prep all the ingredients and keep them ready. In a large bowl, combine the tomatoes, basil, garlic, olive oil and salt.Once the tomatoes are steamed, drain the water from the tomatoes and keep it aside.Place the tomatoes in a bowl and cover it with a lid and allow it to cool down.Heat olive oil in a small pan and add the tomatoes and garlic and sauté until the tomatoes are softened.Serve the Tomato Basil Curry Recipe as a tea time snack along with a cup of water for a weeknight dinner.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "test_ing = \"tomato, basil, garlic, olive oil, salt\"\n",
    "print(generate_recipe(test_ing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "993e0412-3b6e-459d-a149-949372e884b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting rouge_score\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Collecting absl-py\n",
      "  Using cached absl_py-2.2.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: nltk in d:\\anaconda3\\lib\\site-packages (from rouge_score) (3.8.1)\n",
      "Requirement already satisfied: numpy in d:\\anaconda3\\lib\\site-packages (from rouge_score) (1.26.4)\n",
      "Requirement already satisfied: six>=1.14.0 in d:\\anaconda3\\lib\\site-packages (from rouge_score) (1.16.0)"
     ]
    }
   ],
   "source": [
    "!pip install rouge_score absl-py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cd2fda28-bac5-4286-873b-0ed60e313417",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入评估库\n",
    "import evaluate\n",
    "import numpy as np\n",
    "from tqdm import tqdm  # 进度条\n",
    "\n",
    "# 加载指标\n",
    "bleu_metric = evaluate.load(\"bleu\")\n",
    "rouge_metric = evaluate.load(\"rouge\")\n",
    "\n",
    "def evaluate_model(model, tokenizer, eval_dataset, num_samples=50):\n",
    "    \"\"\"\n",
    "    评估模型生成质量（BLEU/ROUGE）和预测准确率\n",
    "    Evaluate model generation quality (BLEU/ROUGE) and prediction accuracy\n",
    "    \"\"\"\n",
    "    model.eval()  # 切换为评估模式\n",
    "    \n",
    "    # 随机选择部分评估数据\n",
    "    eval_samples = eval_dataset.select(range(min(num_samples, len(eval_dataset))))\n",
    "    \n",
    "    # 存储结果\n",
    "    predictions, references = [], []\n",
    "    correct_predictions = 0\n",
    "    \n",
    "    for sample in tqdm(eval_samples, desc=\"Evaluating\"):\n",
    "        # 生成预测\n",
    "        input_text = sample[\"input_text\"]\n",
    "        inputs = tokenizer(input_text, return_tensors=\"pt\").to(model.device)\n",
    "        outputs = model.generate(**inputs, max_length=512)\n",
    "        prediction = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # 获取真实值\n",
    "        target_text = sample[\"target_text\"]\n",
    "        \n",
    "        # 记录结果\n",
    "        predictions.append(prediction)\n",
    "        references.append([target_text])  # BLEU需要reference为列表形式\n",
    "        \n",
    "        # 简单检查菜名是否预测正确（基础准确率）\n",
    "        if \"Recipe name:\" in prediction and \"Recipe name:\" in target_text:\n",
    "            pred_name = prediction.split(\"Recipe name:\")[1].split(\"\\n\")[0].strip()\n",
    "            true_name = target_text.split(\"Recipe name:\")[1].split(\"\\n\")[0].strip()\n",
    "            if pred_name == true_name:\n",
    "                correct_predictions += 1\n",
    "    \n",
    "    # 计算指标\n",
    "    bleu_results = bleu_metric.compute(predictions=predictions, references=references)\n",
    "    rouge_results = rouge_metric.compute(predictions=predictions, references=references)\n",
    "    accuracy = correct_predictions / len(eval_samples)\n",
    "    \n",
    "    return {\n",
    "        \"bleu\": bleu_results[\"bleu\"],\n",
    "        \"rouge1\": rouge_results[\"rouge1\"],\n",
    "        \"rouge2\": rouge_results[\"rouge2\"],\n",
    "        \"rougeL\": rouge_results[\"rougeL\"],\n",
    "        \"name_accuracy\": accuracy\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "d2ca6320-e8fd-4ed6-8ee6-8fb7e145b1f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 50/50 [06:56<00:00,  8.34s/it]\n"
     ]
    }
   ],
   "source": [
    "# 运行评估\n",
    "results = evaluate_model(model, tokenizer, eval_ds, num_samples=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "b5d86835-cd8f-4c07-99f0-e71b4bb0f181",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation result: {'bleu': 0.39356997424306843, 'rouge1': 0.45960177281704033, 'rouge2': 0.32018395568410966, 'rougeL': 0.4106102389669763, 'name_accuracy': 0.73277075}\n"
     ]
    }
   ],
   "source": [
    "print(\"Evaluation result:\",results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
