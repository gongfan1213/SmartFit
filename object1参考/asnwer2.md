ä¸ºäº†è¿›ä¸€æ­¥å¢å¼ºä½ å½“å‰çš„ä»£ç ï¼Œä»¥ä¸‹æ˜¯å‡ ä¸ªæ”¹è¿›å»ºè®®åŠå…¶å¯¹åº”çš„ä»£ç å®ç°ï¼Œèƒ½å¤Ÿåœ¨ Google Colab ä¸Šè¿è¡Œï¼š

### 1. **é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•**
åœ¨æ•°æ®é›†å¤„ç†æˆ–æ¨¡å‹è®­ç»ƒæ—¶ï¼Œå‡ºç°é”™è¯¯çš„å¯èƒ½æ€§è¾ƒå¤§ï¼ŒåŠ å…¥é”™è¯¯å¤„ç†æœºåˆ¶å¯ä»¥å¸®åŠ©æ›´å¥½åœ°è°ƒè¯•å’Œè¿è¡Œä»£ç ã€‚

#### é”™è¯¯å¤„ç†å’Œæ—¥å¿—è®°å½•
```python
import logging

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger()

# ç¤ºä¾‹ï¼šåœ¨æ•°æ®å‡†å¤‡æ—¶æ·»åŠ é”™è¯¯å¤„ç†
try:
    # åŠ è½½æ•°æ®é›†
    image_paths = glob.glob(os.path.join(image_dir, '*.jpg'))
    mask_paths = [os.path.join(mask_dir, os.path.basename(p).replace('.jpg', '.png')) for p in image_paths]
    if len(image_paths) == 0:
        raise ValueError("æ²¡æœ‰æ‰¾åˆ°ä»»ä½•å›¾ç‰‡æ–‡ä»¶ã€‚è¯·æ£€æŸ¥è·¯å¾„ã€‚")
    logger.info(f"Found {len(image_paths)} image files and corresponding masks.")
except Exception as e:
    logger.error(f"Error while preparing dataset: {e}")
    raise
```

### 2. **ä¿å­˜å’ŒåŠ è½½æ¨¡å‹**
ä¿å­˜æ¨¡å‹æ—¶ï¼Œå¯ä»¥è€ƒè™‘ä¸ºå…¶æä¾›ä¸€ä¸ªç‰ˆæœ¬å·æˆ–è€…æ—¶é—´æˆ³ï¼Œä»¥ä¾¿è·Ÿè¸ªä¸åŒç‰ˆæœ¬çš„æ¨¡å‹ã€‚åŒæ—¶ï¼ŒåŠ è½½æ¨¡å‹æ—¶å¯ä»¥ç¡®ä¿è·¯å¾„å­˜åœ¨ã€‚

#### ä¿å­˜å’ŒåŠ è½½æ¨¡å‹
```python
import time

# ä¿å­˜æ¨¡å‹æ—¶ï¼ŒåŠ å…¥æ—¶é—´æˆ³ï¼Œä¾¿äºç®¡ç†
model_save_path = f'/content/models/ingredient_classifier_{int(time.time())}.pth'
torch.save(model.state_dict(), model_save_path)
logger.info(f"æ¨¡å‹å·²ä¿å­˜è‡³ {model_save_path}")

# åŠ è½½æ¨¡å‹
def load_model(model, model_path):
    if os.path.exists(model_path):
        model.load_state_dict(torch.load(model_path))
        model.eval()
        logger.info(f"æ¨¡å‹å·²åŠ è½½ä» {model_path}")
    else:
        logger.error("æ¨¡å‹è·¯å¾„ä¸å­˜åœ¨ï¼Œè¯·æ£€æŸ¥è·¯å¾„")
    return model

# ç¤ºä¾‹ï¼šåŠ è½½ä¹‹å‰ä¿å­˜çš„æ¨¡å‹
model = load_model(model, model_save_path)
```

### 3. **æ›´å¤šè¯„ä¼°æŒ‡æ ‡å’Œæ··æ·†çŸ©é˜µ**
é™¤äº† `precision`ã€`recall` å’Œ `F1` åˆ†æ•°å¤–ï¼Œè¿˜å¯ä»¥åŠ å…¥æ··æ·†çŸ©é˜µå’Œ ROC æ›²çº¿æ¥è¿›ä¸€æ­¥è¯„ä¼°æ¨¡å‹çš„è¡¨ç°ã€‚ä»¥ä¸‹æ˜¯å¦‚ä½•å®ç°æ··æ·†çŸ©é˜µå’Œ ROC æ›²çº¿çš„ä»£ç ï¼š

#### æ·»åŠ æ··æ·†çŸ©é˜µå’ŒROCæ›²çº¿
```python
from sklearn.metrics import confusion_matrix, roc_curve, auc
import seaborn as sns
import matplotlib.pyplot as plt

# æ··æ·†çŸ©é˜µ
def plot_confusion_matrix(labels, preds, class_names):
    cm = confusion_matrix(labels.flatten(), preds.flatten())
    plt.figure(figsize=(10, 8))
    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=class_names, yticklabels=class_names)
    plt.xlabel("Predicted")
    plt.ylabel("True")
    plt.title("Confusion Matrix")
    plt.show()

# ROCæ›²çº¿
def plot_roc_curve(labels, preds, class_names):
    fpr, tpr, thresholds = roc_curve(labels.flatten(), preds.flatten())
    roc_auc = auc(fpr, tpr)
    plt.figure(figsize=(10, 8))
    plt.plot(fpr, tpr, color='blue', lw=2, label='ROC curve (area = %0.2f)' % roc_auc)
    plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')
    plt.xlim([0.0, 1.0])
    plt.ylim([0.0, 1.05])
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC)')
    plt.legend(loc='lower right')
    plt.show()

# è®¡ç®—å¹¶ç»˜åˆ¶è¯„ä¼°å›¾
def evaluate_with_metrics(model, dataloader, class_names, threshold=0.5):
    model.eval()
    all_preds = []
    all_labels = []
    
    with torch.no_grad():
        for imgs, labels in tqdm(dataloader, desc="Evaluating"):
            imgs = imgs.to(device)
            outputs = model(imgs)
            preds = torch.sigmoid(outputs).cpu().numpy()
            labels = labels.numpy()
            
            all_preds.append(preds)
            all_labels.append(labels)
    
    all_preds = np.vstack(all_preds)
    all_labels = np.vstack(all_labels)
    
    # æ··æ·†çŸ©é˜µ
    binary_preds = (all_preds >= threshold).astype(int)
    plot_confusion_matrix(all_labels, binary_preds, class_names)

    # ROCæ›²çº¿
    plot_roc_curve(all_labels, all_preds, class_names)

    # æ‰“å°å…¶ä»–æŒ‡æ ‡
    precision = precision_score(all_labels, binary_preds, average='micro')
    recall = recall_score(all_labels, binary_preds, average='micro')
    f1 = f1_score(all_labels, binary_preds, average='micro')
    
    try:
        auc = roc_auc_score(all_labels, all_preds, average='micro')
    except:
        auc = 'N/A (AUC not defined for this batch)'
    
    print("ğŸ” Evaluation Results:")
    print(f"Precision: {precision:.4f}")
    print(f"Recall:    {recall:.4f}")
    print(f"F1 Score:  {f1:.4f}")
    print(f"AUC:       {auc}")

# ä½¿ç”¨æ–¹å¼
evaluate_with_metrics(model, val_loader, class_names)
```

### 4. **åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡**
åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­ï¼Œå¯ä»¥ä½¿ç”¨ `lr_scheduler` æ¥åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡ï¼Œè¿™æ ·æœ‰åŠ©äºæå‡æ¨¡å‹æ€§èƒ½ã€‚

#### åŠ¨æ€å­¦ä¹ ç‡è°ƒæ•´
```python
from torch.optim.lr_scheduler import StepLR

# å®šä¹‰å­¦ä¹ ç‡è°ƒåº¦å™¨
scheduler = StepLR(optimizer, step_size=5, gamma=0.1)

# åœ¨è®­ç»ƒå¾ªç¯ä¸­ä½¿ç”¨
for epoch in range(num_epochs):
    model.train()
    running_loss = 0.0
    for imgs, labels in tqdm(train_loader, desc=f"Epoch {epoch+1}/{num_epochs} - Training"):
        imgs, labels = imgs.to(device), labels.to(device)
        optimizer.zero_grad()
        outputs = model(imgs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item() * imgs.size(0)
    
    epoch_loss = running_loss / len(train_loader.dataset)
    print(f"Epoch {epoch+1} Training Loss: {epoch_loss:.4f}")
    
    # æ¯ä¸ª epoch åæ›´æ–°å­¦ä¹ ç‡
    scheduler.step()
    
    model.eval()
    val_loss = 0.0
    with torch.no_grad():
        for imgs, labels in tqdm(val_loader, desc="Validation"):
            imgs, labels = imgs.to(device), labels.to(device)
            outputs = model(imgs)
            loss = criterion(outputs, labels)
            val_loss += loss.item() * imgs.size(0)
    
    val_loss /= len(val_loader.dataset)
    print(f"Epoch {epoch+1} Validation Loss: {val_loss:.4f}\n")
```

### æ€»ç»“
- æ·»åŠ äº†æ—¥å¿—è®°å½•å’Œé”™è¯¯å¤„ç†ï¼Œä»¥ä¾¿æ›´å¥½åœ°è·Ÿè¸ªå’Œè°ƒè¯•ä»£ç ã€‚
- æä¾›äº†ä¿å­˜å’ŒåŠ è½½æ¨¡å‹çš„ä»£ç ï¼Œç¡®ä¿å¯ä»¥åœ¨ä¸åŒé˜¶æ®µåŠ è½½æ¨¡å‹è¿›è¡Œæµ‹è¯•ã€‚
- å¢åŠ äº†æ›´å¤šçš„è¯„ä¼°æŒ‡æ ‡ï¼Œå¦‚æ··æ·†çŸ©é˜µå’ŒROCæ›²çº¿ï¼Œå¸®åŠ©ä½ æ›´å…¨é¢åœ°è¯„ä¼°æ¨¡å‹ã€‚
- å¼•å…¥äº†åŠ¨æ€è°ƒæ•´å­¦ä¹ ç‡çš„æœºåˆ¶ï¼Œä»¥ä¼˜åŒ–è®­ç»ƒè¿‡ç¨‹ã€‚

è¿™äº›ä»£ç æ”¹è¿›å¯ä»¥è®©ä½ åœ¨ Google Colab ä¸Šè¿›è¡Œæ›´åŠ é«˜æ•ˆå’Œå¯é çš„è®­ç»ƒå’Œè¯„ä¼°ã€‚
